name: "masked-language-modeling"
objectives: ["masked-lm", "next-sentence-prediction"]  # TODO dummy values so far // where do we store objectives configuration?
learning_rate: 1e-4
weight_decay: 0.01
warmup_steps: 10000
max_steps: 1000000
gradient_accumulation_steps: 1
mlm_probability: 0.15
pad_to_multiple_of: null
# max_grad_norm: 1.0  # todo do we want to use gradient clipping?
fp16: false  # todo change this to true, apparently it does not work on cpu
# fp16_opt_level: "O1"  # todo how do we use this?
