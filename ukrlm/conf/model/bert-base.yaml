name: "bert-base"
checkpoint_path: null
n_layers: 12
attn_heads: 12
hidden_size: 768
feed_forward_size: 3072
dropout_prob: 0.1
activation: "gelu"
layer_norm_eps: 1e-5
max_position_embeddings: 514
vocab_size: 65536